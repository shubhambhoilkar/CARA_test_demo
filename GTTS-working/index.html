<!-- simple wokring but with mic permission every time-->

<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Sam Voice Bot!</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      padding: 2rem;
      background: #f6f7fb;
    }
    h1 {
      text-align: center;
      color: #333;
    }
    #messages {
      background: white;
      border: 1px solid #ccc;
      border-radius: 10px;
      padding: 1rem;
      height: 300px;
      overflow-y: auto;
    }
    .user { color: #0066cc; }
    .bot { color: #009933; }
    button {
      margin-top: 1rem;
      padding: 10px 20px;
      border: none;
      border-radius: 6px;
      background-color: #007bff;
      color: white;
      cursor: pointer;
    }
    button:disabled {
      background: #ccc;
    }
  </style>
</head>
<body>
  <h1>Sam Voice Bot Demo.</h1>
  <div id="messages"></div>

  <button id="startBtn">üéôÔ∏è Start Speaking</button>
  <button id="stopBtn" disabled>üõë Stop</button>

  <script>
    const startBtn = document.getElementById("startBtn");
    const stopBtn = document.getElementById("stopBtn");
    const messagesDiv = document.getElementById("messages");

    const ws = new WebSocket("ws://localhost:9900/ws");
    let mediaRecorder;
    let audioPlayer = new Audio();

    ws.onopen = () => {
      console.log("‚úÖ Connected to backend.");
      addMessage("System", "Connected to voice bot server.");
    };

    ws.onmessage = (event) => {
      const data = JSON.parse(event.data);

      if (data.pause) {
        addMessage("System", "AI speech paused.");
        if (!audioPlayer.paused) {
          audioPlayer.pause();
          audioPlayer.currentTime = 0;
        }
        return;
      }

      if (data.text) addMessage("AI", data.text);

      if (data.audio) {
        const audioSrc = "data:audio/mp3;base64," + data.audio;
        audioPlayer.src = audioSrc;
        audioPlayer.play().catch(err => console.error("Audio play failed", err));
      }
    };

    ws.onclose = () => {
      addMessage("System", "Disconnected from backend.");
    };

    function addMessage(sender, text) {
      const div = document.createElement("div");
      div.className = sender === "AI" ? "bot" : "user";
      div.innerText = `${sender}: ${text}`;
      messagesDiv.appendChild(div);
      messagesDiv.scrollTop = messagesDiv.scrollHeight;
    }

    // Simple browser SpeechRecognition for user input
    let recognition;
    if ("webkitSpeechRecognition" in window) {
      recognition = new webkitSpeechRecognition();
      recognition.lang = "en-US";
      recognition.continuous = false;
      recognition.interimResults = false;

      recognition.onstart = () => {
        addMessage("System", "Listening...");
        startBtn.disabled = true;
        stopBtn.disabled = false;
      };

      recognition.onresult = (event) => {
        const transcript = event.results[0][0].transcript;
        addMessage("You", transcript);
        ws.send(transcript);
      };

      recognition.onerror = (event) => {
        console.error("Speech recognition error:", event.error);
      };

      recognition.onend = () => {
        startBtn.disabled = false;
        stopBtn.disabled = true;
        addMessage("System", "Stopped listening.");
      };
    } else {
      alert("Speech recognition not supported in this browser. Try Chrome.");
    }

    startBtn.onclick = () => recognition.start();
    stopBtn.onclick = () => recognition.stop();
  </script>
</body>
</html>

